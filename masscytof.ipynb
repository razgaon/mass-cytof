{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: / ^C\n",
      "failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n",
      "^C\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pandas==1.3.4\n",
    "!conda install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install torch\n",
    "!pip install pycombat\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/razgaon/projects/condas/cytof/miniconda3/envs/cytof/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engaging\n",
    "# data_dir = f'/home/razgaon/ondemand/data/sys/myjobs/projects/default/3/'\n",
    "# Satori\n",
    "data_dir = f'/home/razgaon/razgaon/'\n",
    "NSCLC_pickle = f'{data_dir}NSCLC_prepared_data_test.pickle'\n",
    "PBMC_pickle = f'{data_dir}PBMC_prepared_data_test.pickle'\n",
    "NSCLC = pd.read_pickle(NSCLC_pickle)\n",
    "PBMC = pd.read_pickle(PBMC_pickle)\n",
    "\n",
    "\n",
    "# Try to add an id that maps to the fcs file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/nobackup/users/razgaon/projects/condas/cytof/miniconda3/envs/cytof/lib/python3.9/site-packages/pandas/core/indexes/base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/nobackup/users/razgaon/projects/condas/cytof/miniconda3/envs/cytof/lib/python3.9/site-packages/pandas/_libs/index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/nobackup/users/razgaon/projects/condas/cytof/miniconda3/envs/cytof/lib/python3.9/site-packages/pandas/_libs/index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mPBMC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/nobackup/users/razgaon/projects/condas/cytof/miniconda3/envs/cytof/lib/python3.9/site-packages/pandas/core/frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3458\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3460\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/nobackup/users/razgaon/projects/condas/cytof/miniconda3/envs/cytof/lib/python3.9/site-packages/pandas/core/indexes/base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[1;32m   3366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "PBMC['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_df = PBMC.sample(100000)\n",
    "NSCLC_df = NSCLC.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if pycombat requires normalization first for each dataset, or after\n",
    "#concat (keep all markers), batch normalize on X with NaNs, umap to confirm quality,  min-max scale, then vae, umap to confirm quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "excluded_markers = ['id', 'Time', 'Eventlength', 'sample', 'batch']\n",
    "\n",
    "PBMC_markers = [col for col in PBMC_df.columns if col not in excluded_markers]\n",
    "PBMC_df[PBMC_markers] = scaler.fit_transform(PBMC_df[PBMC_markers])\n",
    "PBMC_df['source'] = 0\n",
    "\n",
    "NSCLC_markers = [col for col in NSCLC_df.columns if col not in excluded_markers]\n",
    "NSCLC_df[NSCLC_markers] = scaler.fit_transform(NSCLC_df[NSCLC_markers])\n",
    "NSCLC_df['source'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CD11b</th>\n",
       "      <th>Beads</th>\n",
       "      <th>CD80</th>\n",
       "      <th>FoxP3</th>\n",
       "      <th>CD33</th>\n",
       "      <th>CXCR5</th>\n",
       "      <th>CCR6</th>\n",
       "      <th>Gata3</th>\n",
       "      <th>RORgT</th>\n",
       "      <th>...</th>\n",
       "      <th>CCR7</th>\n",
       "      <th>Er168Di</th>\n",
       "      <th>CD38</th>\n",
       "      <th>GITR</th>\n",
       "      <th>CD56</th>\n",
       "      <th>Yb176Di</th>\n",
       "      <th>Os189Di</th>\n",
       "      <th>DNA1</th>\n",
       "      <th>DNA2</th>\n",
       "      <th>Cisplatin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>785943</th>\n",
       "      <td>785944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485537</td>\n",
       "      <td>0.782830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204006</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745519</th>\n",
       "      <td>745520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122072</td>\n",
       "      <td>0.345791</td>\n",
       "      <td>0.204006</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51647</th>\n",
       "      <td>51648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294445</td>\n",
       "      <td>0.167676</td>\n",
       "      <td>0.682063</td>\n",
       "      <td>0.496258</td>\n",
       "      <td>0.345791</td>\n",
       "      <td>0.235161</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110090</th>\n",
       "      <td>1110091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10096</td>\n",
       "      <td>0.069203</td>\n",
       "      <td>0.505993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301696</td>\n",
       "      <td>0.090279</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748812</th>\n",
       "      <td>748813</td>\n",
       "      <td>0.068608</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.090279</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46675</th>\n",
       "      <td>46676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079267</td>\n",
       "      <td>0.061541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321914</td>\n",
       "      <td>0.218055</td>\n",
       "      <td>0.131698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214377</th>\n",
       "      <td>214378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.042198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430598</td>\n",
       "      <td>0.346291</td>\n",
       "      <td>0.050559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122752</th>\n",
       "      <td>122753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.040897</td>\n",
       "      <td>0.314993</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>0.061541</td>\n",
       "      <td>0.079267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376180</td>\n",
       "      <td>0.271845</td>\n",
       "      <td>0.114250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101304</th>\n",
       "      <td>101305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042198</td>\n",
       "      <td>0.042198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343310</td>\n",
       "      <td>0.196315</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155210</th>\n",
       "      <td>155211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407274</td>\n",
       "      <td>0.326861</td>\n",
       "      <td>0.294571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     CD11b    Beads      CD80     FoxP3      CD33     CXCR5  \\\n",
       "785943    785944  0.000000  0.00000  0.000000  0.485537  0.782830  0.000000   \n",
       "745519    745520  0.000000  0.00000  0.000000  0.128126  0.000000  0.000000   \n",
       "51647      51648  0.000000  0.00000  0.000000  0.294445  0.167676  0.682063   \n",
       "1110090  1110091  0.000000  0.10096  0.069203  0.505993  0.000000  0.000000   \n",
       "748812    748813  0.068608  0.00000  0.000000  0.218417  0.000000  0.000000   \n",
       "...          ...       ...      ...       ...       ...       ...       ...   \n",
       "46675      46676       NaN      NaN       NaN       NaN       NaN  0.000000   \n",
       "214377    214378       NaN      NaN       NaN       NaN       NaN  0.000000   \n",
       "122752    122753       NaN      NaN       NaN       NaN       NaN  0.000000   \n",
       "101304    101305       NaN      NaN       NaN       NaN       NaN  0.000000   \n",
       "155210    155211       NaN      NaN       NaN       NaN       NaN  0.000000   \n",
       "\n",
       "             CCR6     Gata3     RORgT  ...      CCR7   Er168Di      CD38  \\\n",
       "785943   0.042640  0.000000  0.204006  ...       NaN       NaN       NaN   \n",
       "745519   0.122072  0.345791  0.204006  ...       NaN       NaN       NaN   \n",
       "51647    0.496258  0.345791  0.235161  ...       NaN       NaN       NaN   \n",
       "1110090  0.000000  0.301696  0.090279  ...       NaN       NaN       NaN   \n",
       "748812   0.000000  0.039188  0.090279  ...       NaN       NaN       NaN   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "46675    0.000000       NaN       NaN  ...  0.000000  0.000000  0.000000   \n",
       "214377   0.028004       NaN       NaN  ...  0.050934  0.000000  0.083122   \n",
       "122752   0.054973       NaN       NaN  ...  0.074282  0.040897  0.314993   \n",
       "101304   0.080172       NaN       NaN  ...  0.291318  0.000000  0.022542   \n",
       "155210   0.000000       NaN       NaN  ...  0.000000  0.040897  0.000000   \n",
       "\n",
       "             GITR      CD56   Yb176Di  Os189Di      DNA1      DNA2  Cisplatin  \n",
       "785943        NaN       NaN       NaN      NaN       NaN       NaN        NaN  \n",
       "745519        NaN       NaN       NaN      NaN       NaN       NaN        NaN  \n",
       "51647         NaN       NaN       NaN      NaN       NaN       NaN        NaN  \n",
       "1110090       NaN       NaN       NaN      NaN       NaN       NaN        NaN  \n",
       "748812        NaN       NaN       NaN      NaN       NaN       NaN        NaN  \n",
       "...           ...       ...       ...      ...       ...       ...        ...  \n",
       "46675    0.000000  0.079267  0.061541      0.0  0.321914  0.218055   0.131698  \n",
       "214377   0.000000  0.021496  0.042198      0.0  0.430598  0.346291   0.050559  \n",
       "122752   0.036253  0.061541  0.079267      0.0  0.376180  0.271845   0.114250  \n",
       "101304   0.000000  0.042198  0.042198      0.0  0.343310  0.196315   0.000000  \n",
       "155210   0.036253  0.021496  0.021496      0.0  0.407274  0.326861   0.294571  \n",
       "\n",
       "[200000 rows x 93 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([PBMC_df, NSCLC_df])\n",
    "df\n",
    "# df.to_csv('original_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    " \n",
    "    def __init__(self,df):\n",
    "        x=df.values\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metals to their marker names to ensure consistency when merging dataframes\n",
    "overlap = list(set(PBMC_markers).intersection(set(NSCLC_markers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markers = NSCLC_markers + PBMC_markers\n",
    "dataset = MyDataset(df[overlap])\n",
    "# # Data loader\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=1000, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, latent_dim=5, hdim=50):\n",
    "        super(VAE, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc1 = nn.Linear(x_dim , hdim)\n",
    "        self.fc21 = nn.Linear(hdim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hdim, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hdim)\n",
    "        self.fc4 = nn.Linear(hdim, x_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x_ = torch.cat([x], dim=-1)\n",
    "        h1 = F.relu(self.fc1(x_))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return self.fc4(h3)\n",
    "    def reparameterize(self, mu, var):\n",
    "#         if self.distance == 'standard':\n",
    "        if self.training:\n",
    "            std = var.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            result = eps.mul(std).add_(mu)\n",
    "            return result\n",
    "        else:\n",
    "            return mu\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.x_dim))\n",
    "        latent = self.reparameterize(mu, logvar)\n",
    "        reconstructed = self.decode(latent)\n",
    "        return reconstructed, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y, device):\n",
    "    x_size = x.to(device).size(0)\n",
    "    y_size = y.to(device).size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1)\n",
    "    y = y.unsqueeze(0)\n",
    "    tiled_x = x.expand(x_size, y_size, dim).to(device)\n",
    "    tiled_y = y.expand(x_size, y_size, dim).to(device)\n",
    "    kernel_input = (tiled_x - tiled_y).pow(2).mean(2)/float(dim)\n",
    "    return torch.exp(-kernel_input)\n",
    "\n",
    "def compute_mmd(x, y, device):\n",
    "    x_kernel = compute_kernel(x, x, device)\n",
    "    y_kernel = compute_kernel(y, y, device)\n",
    "    xy_kernel = compute_kernel(x, y, device)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd\n",
    "\n",
    "def vae_loss_function(inputs, encoded, decoded, true_samples, device):\n",
    "    #reconstruction loss - decoding\n",
    "    nll = (decoded - inputs).pow(2).mean()\n",
    "    #distance + reconstruction loss\n",
    "    mmd = compute_mmd(true_samples, encoded.to(device), device)\n",
    "    return(nll, mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, learning_rate, epochs, train_loader, test_loader, optimizer = 'Adam'):\n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, \n",
    "                              momentum = .95, nesterov = True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0\n",
    "        training_reconstruction_error = 0\n",
    "        training_mmd = 0\n",
    "\n",
    "        net.train()\n",
    "        for batchnum, X in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            reconstruction, mu = net(X)\n",
    "            true_samples = torch.randn(mu.shape)\n",
    "            reconstruction_error, mmd = vae_loss_function(inputs = X, encoded=mu, decoded=reconstruction, true_samples=true_samples , device=device)\n",
    "            loss = reconstruction_error + mmd\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            training_reconstruction_error += reconstruction_error\n",
    "            training_mmd  += mmd\n",
    "            training_loss += loss\n",
    "\n",
    "        training_reconstruction_error /= (batchnum+1)\n",
    "        training_mmd  /= (batchnum+1)\n",
    "        training_loss /= (batchnum+1)\n",
    "        print('Training loss for epoch %i is %.8f, Reconstruction is %.8f, mmd is %.8f'%(epoch, training_loss, training_reconstruction_error, training_mmd) )\n",
    "        \n",
    "        #Testing loop\n",
    "\n",
    "        testing_reconstruction_error = 0\n",
    "        testing_mmd = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batchnum, X in enumerate(test_loader):\n",
    "                reconstruction, mu = net(X)\n",
    "                true_samples = torch.randn(mu.shape)\n",
    "                reconstruction_error, mmd = vae_loss_function(inputs = X, encoded=mu, decoded=reconstruction, true_samples=true_samples , device=device)\n",
    "\n",
    "                testing_reconstruction_error += reconstruction_error\n",
    "                testing_mmd += mmd\n",
    "            \n",
    "            testing_reconstruction_error /= (batchnum+1)\n",
    "            testing_mmd /= (batchnum+1)\n",
    "            print('Testing loss for epoch %i is %.8f, Reconstruction is %.8f, mmd is %.8f'%(epoch, testing_reconstruction_error + testing_mmd, testing_reconstruction_error, testing_mmd) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VAE(x_dim=dataset.x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 0 is 0.10110502, Reconstruction is 0.09657765, mmd is 0.00452731\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, learning_rate, epochs, train_loader, test_loader, optimizer)\u001b[0m\n\u001b[1;32m     40\u001b[0m reconstruction, mu \u001b[38;5;241m=\u001b[39m net(X)\n\u001b[1;32m     41\u001b[0m true_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(mu\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 42\u001b[0m reconstruction_error, mmd \u001b[38;5;241m=\u001b[39m \u001b[43mvae_loss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreconstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_samples\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m testing_reconstruction_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reconstruction_error\n\u001b[1;32m     45\u001b[0m testing_mmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mmd\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mvae_loss_function\u001b[0;34m(inputs, encoded, decoded, true_samples, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m nll \u001b[38;5;241m=\u001b[39m (decoded \u001b[38;5;241m-\u001b[39m inputs)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#distance + reconstruction loss\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m mmd \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(nll, mmd)\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mcompute_mmd\u001b[0;34m(x, y, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m x_kernel \u001b[38;5;241m=\u001b[39m compute_kernel(x, x, device)\n\u001b[1;32m     14\u001b[0m y_kernel \u001b[38;5;241m=\u001b[39m compute_kernel(y, y, device)\n\u001b[0;32m---> 15\u001b[0m xy_kernel \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m mmd \u001b[38;5;241m=\u001b[39m x_kernel\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m+\u001b[39m y_kernel\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mxy_kernel\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mmd\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mcompute_kernel\u001b[0;34m(x, y, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m tiled_x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mexpand(x_size, y_size, dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m tiled_y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mexpand(x_size, y_size, dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m kernel_input \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtiled_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtiled_y\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(dim)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mkernel_input)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(net, learning_rate = .0001, epochs = 30,\n",
    "      train_loader = train_loader, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'model_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=13, out_features=50, bias=True)\n",
       "  (fc21): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (fc22): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (fc3): Linear(in_features=5, out_features=50, bias=True)\n",
       "  (fc4): Linear(in_features=50, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load('model_state')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1200, 0.0000, 0.0334,  ..., 0.6372, 0.6633, 0.0000],\n",
       "        [0.5676, 0.0000, 0.2571,  ..., 0.7047, 0.3044, 0.0484],\n",
       "        [0.1200, 0.0000, 0.0656,  ..., 0.5747, 0.3217, 0.0000],\n",
       "        ...,\n",
       "        [0.5077, 0.2861, 0.0000,  ..., 0.0000, 0.2371, 0.2309],\n",
       "        [0.3052, 0.3126, 0.0000,  ..., 0.0000, 0.2145, 0.2309],\n",
       "        [0.3496, 0.3704, 0.1016,  ..., 0.5858, 0.0696, 0.4264]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, latent = model(dataset.x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df = pd.DataFrame(latent.detach().cpu().numpy(), index = df.index)\n",
    "latent_df['source'] = df.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df.to_pickle('latent.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200000, 5])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(dataset.x_train.detach().cpu().numpy(), index = df.index)\n",
    "x_train['source'] = df.source\n",
    "x_train.to_pickle('x_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cytof2",
   "language": "python",
   "name": "cytof2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
