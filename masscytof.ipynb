{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.3.4\n",
      "  Downloading pandas-1.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 3.7 MB/s eta 0:00:01    |▊                               | 245 kB 3.7 MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/ifrah/.conda/envs/cytof/lib/python3.8/site-packages (from pandas==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ifrah/.conda/envs/cytof/lib/python3.8/site-packages (from pandas==1.3.4) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ifrah/.conda/envs/cytof/lib/python3.8/site-packages (from pandas==1.3.4) (1.19.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ifrah/.conda/envs/cytof/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas==1.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install fcsparser\n",
    "# !pip install pandas\n",
    "# !pip install scanpy\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF this doesn't work, try reading fcs natively using python\n",
    "data_dir = f'/home/razgaon/ondemand/data/sys/myjobs/projects/default/3/'\n",
    "NSCLC_pickle = f'{data_dir}NSCLC_prepared_data_test.pickle'\n",
    "PBMC_pickle = f'{data_dir}PBMC_prepared_data_test.pickle'\n",
    "NSCLC = pd.read_pickle(NSCLC_pickle)\n",
    "PBMC = pd.read_pickle(PBMC_pickle)\n",
    "\n",
    "\n",
    "# Try to add an id that maps to the fcs file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_df = PBMC.sample(100000)\n",
    "NSCLC_df = NSCLC.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "excluded_markers = ['id', 'Time', 'Eventlength', 'sample', 'batch']\n",
    "NSCLC_markers = [col for col in NSCLC_df.columns if col not in excluded_markers]\n",
    "NSCLC_df[NSCLC_markers] = scaler.fit_transform(NSCLC_df[NSCLC_markers])\n",
    "\n",
    "PBMC_markers = [col for col in PBMC_df.columns if col not in excluded_markers]\n",
    "PBMC_df[PBMC_markers] = scaler.fit_transform(PBMC_df[PBMC_markers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([PBMC_df, NSCLC_df])\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    " \n",
    "    def __init__(self,df):\n",
    "        x=df.values\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD4589</th>\n",
       "      <th>CD45115</th>\n",
       "      <th>Xe131Di</th>\n",
       "      <th>Cs133Di</th>\n",
       "      <th>La139Di</th>\n",
       "      <th>Ce140Di</th>\n",
       "      <th>CCR6</th>\n",
       "      <th>Nd142Di</th>\n",
       "      <th>Ce142Di</th>\n",
       "      <th>CD45RA</th>\n",
       "      <th>...</th>\n",
       "      <th>CXCR3</th>\n",
       "      <th>CD3</th>\n",
       "      <th>EOMES</th>\n",
       "      <th>CD25</th>\n",
       "      <th>HuCD45</th>\n",
       "      <th>Blimp1</th>\n",
       "      <th>CD34</th>\n",
       "      <th>Tbet</th>\n",
       "      <th>CD4</th>\n",
       "      <th>CD127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534716</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051772</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>0.488801</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928442</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229658</td>\n",
       "      <td>0.654777</td>\n",
       "      <td>0.232007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504192</td>\n",
       "      <td>0.206348</td>\n",
       "      <td>0.101685</td>\n",
       "      <td>0.578465</td>\n",
       "      <td>0.235356</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031984</td>\n",
       "      <td>0.067008</td>\n",
       "      <td>0.169429</td>\n",
       "      <td>0.489926</td>\n",
       "      <td>0.091316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99922</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148218</td>\n",
       "      <td>0.458496</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446984</td>\n",
       "      <td>0.091316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>0.383272</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894827</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190910</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>0.232007</td>\n",
       "      <td>0.065044</td>\n",
       "      <td>0.389667</td>\n",
       "      <td>0.091316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740497</td>\n",
       "      <td>0.262387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CD4589  CD45115  Xe131Di  Cs133Di  La139Di  Ce140Di      CCR6  \\\n",
       "534716     0.0      0.0      0.0      0.0      0.0      0.0  0.000000   \n",
       "928442     0.0      0.0      0.0      0.0      0.0      0.0  0.000000   \n",
       "470436     0.0      0.0      0.0      0.0      0.0      0.0  0.666494   \n",
       "99922      0.0      0.0      0.0      0.0      0.0      0.0  0.000000   \n",
       "894827     0.0      0.0      0.0      0.0      0.0      0.0  0.148435   \n",
       "\n",
       "        Nd142Di  Ce142Di    CD45RA  ...     CXCR3       CD3     EOMES  \\\n",
       "534716      0.0      0.0  0.000000  ...  0.051772  0.091566  0.034135   \n",
       "928442      0.0      0.0  0.356892  ...  0.229658  0.654777  0.232007   \n",
       "470436      0.0      0.0  0.786090  ...  0.000000  0.031984  0.067008   \n",
       "99922       0.0      0.0  0.470774  ...  0.148218  0.458496  0.034135   \n",
       "894827      0.0      0.0  0.728323  ...  0.190910  0.411366  0.232007   \n",
       "\n",
       "            CD25    HuCD45    Blimp1      CD34      Tbet       CD4  CD127  \n",
       "534716  0.000000  0.395480  0.000000  0.000000  0.038084  0.488801    0.0  \n",
       "928442  0.000000  0.504192  0.206348  0.101685  0.578465  0.235356    0.0  \n",
       "470436  0.169429  0.489926  0.091316  0.000000  0.038084  0.000000    0.0  \n",
       "99922   0.000000  0.446984  0.091316  0.000000  0.038084  0.383272    0.0  \n",
       "894827  0.065044  0.389667  0.091316  0.000000  0.740497  0.262387    0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metals to their marker names to ensure consistency when merging dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = NSCLC_markers + PBMC_markers\n",
    "dataset = MyDataset(df[markers])\n",
    "# # Data loader\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, latent_dim=5, hdim=50):\n",
    "        super(VAE, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc1 = nn.Linear(x_dim , hdim)\n",
    "        self.fc21 = nn.Linear(hdim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hdim, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hdim)\n",
    "        self.fc4 = nn.Linear(hdim, x_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x_ = torch.cat([x], dim=-1)\n",
    "        h1 = F.relu(self.fc1(x_))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return self.fc4(h3)\n",
    "    def reparameterize(self, mu, var):\n",
    "#         if self.distance == 'standard':\n",
    "        if self.training:\n",
    "            std = var.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            result = eps.mul(std).add_(mu)\n",
    "            return result\n",
    "        else:\n",
    "            return mu\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.x_dim))\n",
    "        latent = self.reparameterize(mu, logvar)\n",
    "        reconstructed = self.decode(latent)\n",
    "        return reconstructed, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y, device):\n",
    "    x_size = x.to(device).size(0)\n",
    "    y_size = y.to(device).size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1)\n",
    "    y = y.unsqueeze(0)\n",
    "    tiled_x = x.expand(x_size, y_size, dim).to(device)\n",
    "    tiled_y = y.expand(x_size, y_size, dim).to(device)\n",
    "    kernel_input = (tiled_x - tiled_y).pow(2).mean(2)/float(dim)\n",
    "    return torch.exp(-kernel_input)\n",
    "\n",
    "def compute_mmd(x, y, device):\n",
    "    x_kernel = compute_kernel(x, x, device)\n",
    "    y_kernel = compute_kernel(y, y, device)\n",
    "    xy_kernel = compute_kernel(x, y, device)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd\n",
    "\n",
    "def vae_loss_function(inputs, encoded, decoded, true_samples, device):\n",
    "    #reconstruction loss - decoding\n",
    "    nll = (decoded - inputs).pow(2).mean()\n",
    "    #distance + reconstruction loss\n",
    "    mmd = compute_mmd(true_samples, encoded.to(device), device)\n",
    "    return(nll, mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, learning_rate, epochs, train_loader, test_loader, optimizer = 'Adam'):\n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, \n",
    "                              momentum = .95, nesterov = True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0\n",
    "        training_reconstruction_error = 0\n",
    "        training_mmd = 0\n",
    "\n",
    "        net.train()\n",
    "        for batchnum, X in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            reconstruction, mu = net(X)\n",
    "            true_samples = torch.randn(mu.shape)\n",
    "            reconstruction_error, mmd = vae_loss_function(inputs = X, encoded=mu, decoded=reconstruction, true_samples=true_samples , device=device)\n",
    "            loss = reconstruction_error + mmd\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            training_reconstruction_error += reconstruction_error\n",
    "            training_mmd  += mmd\n",
    "            training_loss += loss\n",
    "\n",
    "        training_reconstruction_error /= (batchnum+1)\n",
    "        training_mmd  /= (batchnum+1)\n",
    "        training_loss /= (batchnum+1)\n",
    "        print('Training loss for epoch %i is %.8f, Reconstruction is %.8f, mmd is %.8f'%(epoch, training_loss, training_reconstruction_error, training_mmd) )\n",
    "        \n",
    "        #Testing loop\n",
    "\n",
    "        testing_reconstruction_error = 0\n",
    "        testing_mmd = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batchnum, X in enumerate(test_loader):\n",
    "                reconstruction, mu = net(X)\n",
    "                true_samples = torch.randn(mu.shape)\n",
    "                reconstruction_error, mmd = vae_loss_function(inputs = X, encoded=mu, decoded=reconstruction, true_samples=true_samples , device=device)\n",
    "\n",
    "                testing_reconstruction_error += reconstruction_error\n",
    "                testing_mmd += mmd\n",
    "            \n",
    "            testing_reconstruction_error /= (batchnum+1)\n",
    "            testing_mmd /= (batchnum+1)\n",
    "            print('Testing loss for epoch %i is %.8f, Reconstruction is %.8f, mmd is %.8f'%(epoch, testing_reconstruction_error + testing_mmd, testing_reconstruction_error, testing_mmd) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VAE(x_dim=dataset.x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 0 is 0.08995236, Reconstruction is 0.08726753, mmd is 0.00268484\n",
      "Testing loss for epoch 0 is 0.06324264, Reconstruction is 0.06110317, mmd is 0.00213947\n",
      "Training loss for epoch 1 is 0.05268922, Reconstruction is 0.05067399, mmd is 0.00201523\n",
      "Testing loss for epoch 1 is 0.04492477, Reconstruction is 0.04328489, mmd is 0.00163988\n",
      "Training loss for epoch 2 is 0.04054273, Reconstruction is 0.03918091, mmd is 0.00136181\n",
      "Testing loss for epoch 2 is 0.03671294, Reconstruction is 0.03562937, mmd is 0.00108358\n",
      "Training loss for epoch 3 is 0.03296812, Reconstruction is 0.03182631, mmd is 0.00114180\n",
      "Testing loss for epoch 3 is 0.02909335, Reconstruction is 0.02762455, mmd is 0.00146879\n",
      "Training loss for epoch 4 is 0.02676261, Reconstruction is 0.02471765, mmd is 0.00204496\n",
      "Testing loss for epoch 4 is 0.02507382, Reconstruction is 0.02258817, mmd is 0.00248565\n",
      "Training loss for epoch 5 is 0.02386331, Reconstruction is 0.02142551, mmd is 0.00243780\n",
      "Testing loss for epoch 5 is 0.02289333, Reconstruction is 0.02040670, mmd is 0.00248663\n",
      "Training loss for epoch 6 is 0.02213972, Reconstruction is 0.01964621, mmd is 0.00249350\n",
      "Testing loss for epoch 6 is 0.02136219, Reconstruction is 0.01895962, mmd is 0.00240256\n",
      "Training loss for epoch 7 is 0.02082958, Reconstruction is 0.01843048, mmd is 0.00239910\n",
      "Testing loss for epoch 7 is 0.02037184, Reconstruction is 0.01797198, mmd is 0.00239987\n",
      "Training loss for epoch 8 is 0.01995783, Reconstruction is 0.01760722, mmd is 0.00235061\n",
      "Testing loss for epoch 8 is 0.01961660, Reconstruction is 0.01730163, mmd is 0.00231497\n",
      "Training loss for epoch 9 is 0.01925750, Reconstruction is 0.01707421, mmd is 0.00218329\n",
      "Testing loss for epoch 9 is 0.01892638, Reconstruction is 0.01687187, mmd is 0.00205451\n",
      "Training loss for epoch 10 is 0.01861945, Reconstruction is 0.01671948, mmd is 0.00189997\n",
      "Testing loss for epoch 10 is 0.01820218, Reconstruction is 0.01656724, mmd is 0.00163494\n",
      "Training loss for epoch 11 is 0.01782060, Reconstruction is 0.01643769, mmd is 0.00138291\n",
      "Testing loss for epoch 11 is 0.01744104, Reconstruction is 0.01631784, mmd is 0.00112320\n",
      "Training loss for epoch 12 is 0.01717972, Reconstruction is 0.01620540, mmd is 0.00097432\n",
      "Testing loss for epoch 12 is 0.01694930, Reconstruction is 0.01608172, mmd is 0.00086758\n",
      "Training loss for epoch 13 is 0.01677603, Reconstruction is 0.01597068, mmd is 0.00080535\n",
      "Testing loss for epoch 13 is 0.01659800, Reconstruction is 0.01586055, mmd is 0.00073745\n",
      "Training loss for epoch 14 is 0.01650032, Reconstruction is 0.01577001, mmd is 0.00073030\n",
      "Testing loss for epoch 14 is 0.01644899, Reconstruction is 0.01568023, mmd is 0.00076876\n",
      "Training loss for epoch 15 is 0.01637825, Reconstruction is 0.01561004, mmd is 0.00076822\n",
      "Testing loss for epoch 15 is 0.01622980, Reconstruction is 0.01553638, mmd is 0.00069342\n",
      "Training loss for epoch 16 is 0.01619732, Reconstruction is 0.01546800, mmd is 0.00072930\n",
      "Testing loss for epoch 16 is 0.01608534, Reconstruction is 0.01540542, mmd is 0.00067993\n",
      "Training loss for epoch 17 is 0.01602402, Reconstruction is 0.01534315, mmd is 0.00068086\n",
      "Testing loss for epoch 17 is 0.01596782, Reconstruction is 0.01528045, mmd is 0.00068737\n",
      "Training loss for epoch 18 is 0.01588751, Reconstruction is 0.01523417, mmd is 0.00065334\n",
      "Testing loss for epoch 18 is 0.01589554, Reconstruction is 0.01518608, mmd is 0.00070946\n",
      "Training loss for epoch 19 is 0.01578871, Reconstruction is 0.01513400, mmd is 0.00065471\n",
      "Testing loss for epoch 19 is 0.01577648, Reconstruction is 0.01509096, mmd is 0.00068552\n",
      "Training loss for epoch 20 is 0.01570340, Reconstruction is 0.01504267, mmd is 0.00066072\n",
      "Testing loss for epoch 20 is 0.01565459, Reconstruction is 0.01500311, mmd is 0.00065148\n",
      "Training loss for epoch 21 is 0.01560501, Reconstruction is 0.01496126, mmd is 0.00064375\n",
      "Testing loss for epoch 21 is 0.01555708, Reconstruction is 0.01491796, mmd is 0.00063912\n",
      "Training loss for epoch 22 is 0.01553553, Reconstruction is 0.01488125, mmd is 0.00065428\n",
      "Testing loss for epoch 22 is 0.01546844, Reconstruction is 0.01484704, mmd is 0.00062140\n",
      "Training loss for epoch 23 is 0.01543842, Reconstruction is 0.01480654, mmd is 0.00063188\n",
      "Testing loss for epoch 23 is 0.01540016, Reconstruction is 0.01476721, mmd is 0.00063295\n",
      "Training loss for epoch 24 is 0.01540711, Reconstruction is 0.01473284, mmd is 0.00067428\n",
      "Testing loss for epoch 24 is 0.01534781, Reconstruction is 0.01469654, mmd is 0.00065127\n",
      "Training loss for epoch 25 is 0.01529680, Reconstruction is 0.01466339, mmd is 0.00063341\n",
      "Testing loss for epoch 25 is 0.01532257, Reconstruction is 0.01462616, mmd is 0.00069641\n",
      "Training loss for epoch 26 is 0.01521123, Reconstruction is 0.01459217, mmd is 0.00061906\n",
      "Testing loss for epoch 26 is 0.01523219, Reconstruction is 0.01455855, mmd is 0.00067364\n",
      "Training loss for epoch 27 is 0.01512450, Reconstruction is 0.01451915, mmd is 0.00060535\n",
      "Testing loss for epoch 27 is 0.01512972, Reconstruction is 0.01449515, mmd is 0.00063458\n",
      "Training loss for epoch 28 is 0.01510045, Reconstruction is 0.01444791, mmd is 0.00065254\n",
      "Testing loss for epoch 28 is 0.01503620, Reconstruction is 0.01439848, mmd is 0.00063772\n",
      "Training loss for epoch 29 is 0.01502614, Reconstruction is 0.01436252, mmd is 0.00066362\n",
      "Testing loss for epoch 29 is 0.01500670, Reconstruction is 0.01432637, mmd is 0.00068033\n"
     ]
    }
   ],
   "source": [
    "train(net, learning_rate = .0001, epochs = 30,\n",
    "      train_loader = train_loader, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'model_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (fc21): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (fc22): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (fc3): Linear(in_features=5, out_features=50, bias=True)\n",
       "  (fc4): Linear(in_features=50, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load('model_state')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-02a7a02e2ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "r, latent = net(train_loader[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2aab64b1b3d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
