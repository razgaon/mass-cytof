{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.3.4\n",
      "  Downloading pandas-1.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 3.7 MB/s eta 0:00:01    |▊                               | 245 kB 3.7 MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/ifrah/.conda/envs/cytof/lib/python3.8/site-packages (from pandas==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ifrah/.conda/envs/cytof/lib/python3.8/site-packages (from pandas==1.3.4) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ifrah/.conda/envs/cytof/lib/python3.8/site-packages (from pandas==1.3.4) (1.19.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ifrah/.conda/envs/cytof/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas==1.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fcsparser\n",
    "# !pip install pandas\n",
    "# !pip install scanpy\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export TF_BINARY_URL=https://files.pythonhosted.org/packages/dc/65/a94519cd8b4fd61a7b002cb752bfc0c0e5faa25d1f43ec4f0a4705020126/tensorflow-1.15.0-cp37-cp37m-macosx_10_11_x86_64.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF this doesn't work, try reading fcs natively using python\n",
    "data_dir = f'/home/razgaon/ondemand/data/sys/myjobs/projects/default/3/'\n",
    "NSCLC_pickle = f'{data_dir}NSCLC_prepared_data_test.pickle'\n",
    "PBMC_pickle = f'{data_dir}PBMC_prepared_data_test.pickle'\n",
    "NSCLC = pd.read_pickle(NSCLC_pickle)\n",
    "PBMC = pd.read_pickle(PBMC_pickle)\n",
    "\n",
    "\n",
    "# Try to add an id that maps to the fcs file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_df = PBMC.sample(100000)\n",
    "PBMC_df = NSCLC.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "excluded_markers = ['id', 'Time', 'Eventlength', 'sample', 'batch']\n",
    "NSCLC_markers = [col for col in NSCLC_df.columns if col not in excluded_markers]\n",
    "NSCLC_df[NSCLC_markers] = scaler.fit_transform(NSCLC_df[NSCLC_markers])\n",
    "\n",
    "PBMC_markers = [col for col in PBMC_df.columns if col not in excluded_markers]\n",
    "PBMC_df[PBMC_markers] = scaler.fit_transform(PBMC_df[PBMC_markers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([PBMC_df, NSCLC_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    " \n",
    "    def __init__(self,df):\n",
    "        x=df[markers].values\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metals to their marker names to ensure consistency when merging dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = NSCLC_markers + PBMC_markers\n",
    "dataset = MyDataset(df[markers])\n",
    "# # Data loader\n",
    "train_loader = DataLoader(dataset, batch_size=10000, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=10000, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C  D   E    F    G    H\n",
       "0  1.0  2.0  3.0  4   5  NaN  NaN  NaN\n",
       "1  6.0  7.0  8.0  9  10  NaN  NaN  NaN\n",
       "0  NaN  NaN  NaN  4   5  1.0  2.0  3.0\n",
       "1  NaN  NaN  NaN  9  10  6.0  7.0  8.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstration of merging dataframes using concatenation\n",
    "df1 = pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10]], columns = [\"A\", \"B\", \"C\", \"D\", \"E\"])\n",
    "df2 = pd.DataFrame([[1,2,3,4,5],[6,7,8,9,10]], columns = [\"F\", \"G\", \"H\", \"D\", \"E\"])\n",
    "x = pd.concat([df1, df2])\n",
    "x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, latent_dim=5, hdim=50):\n",
    "        super(VAE, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc1 = nn.Linear(x_dim , hdim)\n",
    "        self.fc21 = nn.Linear(hdim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hdim, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hdim)\n",
    "        self.fc4 = nn.Linear(hdim, x_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x_ = torch.cat([x], dim=-1)\n",
    "        h1 = F.relu(self.fc1(x_))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return self.fc4(h3)\n",
    "    def reparameterize(self, mu, var):\n",
    "#         if self.distance == 'standard':\n",
    "        if self.training:\n",
    "            std = var.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            result = eps.mul(std).add_(mu)\n",
    "            return result\n",
    "        else:\n",
    "            return mu\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.x_dim))\n",
    "        latent = self.reparameterize(mu, logvar)\n",
    "        reconstructed = self.decode(latent)\n",
    "        return reconstructed, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y, device):\n",
    "    x_size = x.to(device).size(0)\n",
    "    y_size = y.to(device).size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1)\n",
    "    y = y.unsqueeze(0)\n",
    "    tiled_x = x.expand(x_size, y_size, dim).to(device)\n",
    "    tiled_y = y.expand(x_size, y_size, dim).to(device)\n",
    "    kernel_input = (tiled_x - tiled_y).pow(2).mean(2)/float(dim)\n",
    "    return torch.exp(-kernel_input)\n",
    "\n",
    "def compute_mmd(x, y, device):\n",
    "    x_kernel = compute_kernel(x, x, device)\n",
    "    y_kernel = compute_kernel(y, y, device)\n",
    "    xy_kernel = compute_kernel(x, y, device)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd\n",
    "\n",
    "def vae_loss_function(inputs, encoded, decoded, true_samples, device):\n",
    "    #reconstruction loss - decoding\n",
    "    nll = (decoded - inputs).pow(2).mean()\n",
    "    #distance + reconstruction loss\n",
    "    mmd = compute_mmd(true_samples, encoded.to(device), device)\n",
    "    return(nll, mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, learning_rate, epochs, train_loader, test_loader, optimizer = 'Adam'):\n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, \n",
    "                              momentum = .95, nesterov = True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0\n",
    "        training_reconstruction_error = 0\n",
    "        training_mmd = 0\n",
    "\n",
    "        net.train()\n",
    "        for batchnum, X in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            reconstruction, mu = net(X)\n",
    "            true_samples = torch.randn(mu.shape)\n",
    "            reconstruction_error, mmd = vae_loss_function(inputs = X, encoded=mu, decoded=reconstruction, true_samples=true_samples , device=device)\n",
    "            loss = reconstruction_error + mmd\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            training_reconstruction_error += reconstruction_error\n",
    "            training_mmd  += mmd\n",
    "            training_loss += loss\n",
    "\n",
    "        training_reconstruction_error /= (batchnum+1)\n",
    "        training_mmd  /= (batchnum+1)\n",
    "        training_loss /= (batchnum+1)\n",
    "        print('Training loss for epoch %i is %.8f, Reconstruction is %.8f, mmd is %.8f'%(epoch, training_loss, training_reconstruction_error, training_mmd) )\n",
    "        \n",
    "        #Testing loop\n",
    "\n",
    "        testing_reconstruction_error = 0\n",
    "        testing_mmd = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batchnum, X in enumerate(test_loader):\n",
    "                reconstruction, mu = net(X)\n",
    "                true_samples = torch.randn(mu.shape)\n",
    "                reconstruction_error, mmd = vae_loss_function(inputs = X, encoded=mu, decoded=reconstruction, true_samples=true_samples , device=device)\n",
    "\n",
    "                testing_reconstruction_error += reconstruction_error\n",
    "                testing_mmd += mmd\n",
    "            \n",
    "            testing_reconstruction_error /= (batchnum+1)\n",
    "            testing_mmd /= (batchnum+1)\n",
    "            print('Testing loss for epoch %i is %.8f, Reconstruction is %.8f, mmd is %.8f'%(epoch, testing_reconstruction_error + testing_mmd, testing_reconstruction_error, testing_mmd) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VAE(x_dim=dataset.x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 0 is 0.11626394, Reconstruction is 0.11567972, mmd is 0.00058423\n",
      "Testing loss for epoch 0 is 0.10477105, Reconstruction is 0.10426947, mmd is 0.00050157\n",
      "Training loss for epoch 1 is 0.09631941, Reconstruction is 0.09555338, mmd is 0.00076602\n",
      "Testing loss for epoch 1 is 0.08838500, Reconstruction is 0.08712639, mmd is 0.00125861\n",
      "Training loss for epoch 2 is 0.08261578, Reconstruction is 0.08079699, mmd is 0.00181878\n",
      "Testing loss for epoch 2 is 0.07732584, Reconstruction is 0.07493477, mmd is 0.00239107\n",
      "Training loss for epoch 3 is 0.07329013, Reconstruction is 0.07063015, mmd is 0.00265998\n",
      "Testing loss for epoch 3 is 0.06939243, Reconstruction is 0.06649832, mmd is 0.00289411\n",
      "Training loss for epoch 4 is 0.06618740, Reconstruction is 0.06331658, mmd is 0.00287082\n",
      "Testing loss for epoch 4 is 0.06291854, Reconstruction is 0.06016003, mmd is 0.00275852\n",
      "Training loss for epoch 5 is 0.06009661, Reconstruction is 0.05760598, mmd is 0.00249063\n",
      "Testing loss for epoch 5 is 0.05731266, Reconstruction is 0.05503668, mmd is 0.00227598\n",
      "Training loss for epoch 6 is 0.05492808, Reconstruction is 0.05286604, mmd is 0.00206204\n",
      "Testing loss for epoch 6 is 0.05248811, Reconstruction is 0.05064199, mmd is 0.00184612\n",
      "Training loss for epoch 7 is 0.05033368, Reconstruction is 0.04872710, mmd is 0.00160657\n",
      "Testing loss for epoch 7 is 0.04821482, Reconstruction is 0.04677893, mmd is 0.00143589\n",
      "Training loss for epoch 8 is 0.04641873, Reconstruction is 0.04515485, mmd is 0.00126387\n",
      "Testing loss for epoch 8 is 0.04463834, Reconstruction is 0.04348818, mmd is 0.00115016\n",
      "Training loss for epoch 9 is 0.04313662, Reconstruction is 0.04207474, mmd is 0.00106188\n",
      "Testing loss for epoch 9 is 0.04156394, Reconstruction is 0.04067787, mmd is 0.00088607\n",
      "Training loss for epoch 10 is 0.04026302, Reconstruction is 0.03944081, mmd is 0.00082222\n",
      "Testing loss for epoch 10 is 0.03895465, Reconstruction is 0.03823651, mmd is 0.00071814\n",
      "Training loss for epoch 11 is 0.03781520, Reconstruction is 0.03718884, mmd is 0.00062637\n",
      "Testing loss for epoch 11 is 0.03674694, Reconstruction is 0.03613769, mmd is 0.00060925\n"
     ]
    }
   ],
   "source": [
    "train(net, learning_rate = .0001, epochs = 30,\n",
    "      train_loader = train_loader, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
