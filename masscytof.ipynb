{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas==1.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pycombat in /home/razgaon/.local/lib/python3.8/site-packages (0.20)\n",
      "Requirement already satisfied: scikit-learn in /nfs/software001/home/software/anaconda3/2020.11/lib/python3.8/site-packages (from pycombat) (0.23.2)\n",
      "Requirement already satisfied: numpy in /home/razgaon/.local/lib/python3.8/site-packages (from pycombat) (1.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /nfs/software001/home/software/anaconda3/2020.11/lib/python3.8/site-packages (from scikit-learn->pycombat) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /nfs/software001/home/software/anaconda3/2020.11/lib/python3.8/site-packages (from scikit-learn->pycombat) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /nfs/software001/home/software/anaconda3/2020.11/lib/python3.8/site-packages (from scikit-learn->pycombat) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install fcsparser\n",
    "# !pip install pandas\n",
    "# !pip install scanpy\n",
    "# !pip install torch\n",
    "!pip install pycombat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF this doesn't work, try reading fcs natively using python\n",
    "data_dir = f'/home/razgaon/ondemand/data/sys/myjobs/projects/default/3/'\n",
    "NSCLC_pickle = f'{data_dir}NSCLC_prepared_data_test.pickle'\n",
    "PBMC_pickle = f'{data_dir}PBMC_prepared_data_test.pickle'\n",
    "NSCLC = pd.read_pickle(NSCLC_pickle)\n",
    "PBMC = pd.read_pickle(PBMC_pickle)\n",
    "\n",
    "\n",
    "# Try to add an id that maps to the fcs file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_df = PBMC.sample(100000)\n",
    "NSCLC_df = NSCLC.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if pycombat requires normalization first for each dataset, or after\n",
    "#concat (keep all markers), batch normalize on X with NaNs, umap to confirm quality,  min-max scale, then vae, umap to confirm quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "excluded_markers = ['id', 'Time', 'Eventlength', 'sample', 'batch']\n",
    "NSCLC_markers = [col for col in NSCLC_df.columns if col not in excluded_markers]\n",
    "NSCLC_df[NSCLC_markers] = scaler.fit_transform(NSCLC_df[NSCLC_markers])\n",
    "\n",
    "PBMC_markers = [col for col in PBMC_df.columns if col not in excluded_markers]\n",
    "PBMC_df[PBMC_markers] = scaler.fit_transform(PBMC_df[PBMC_markers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([PBMC_df, NSCLC_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    " \n",
    "    def __init__(self,df):\n",
    "        x=df.values\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metals to their marker names to ensure consistency when merging dataframes\n",
    "overlap = list(set(PBMC_markers).intersection(set(NSCLC_markers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HLADR</th>\n",
       "      <th>CTLA4</th>\n",
       "      <th>CD25</th>\n",
       "      <th>CXCR5</th>\n",
       "      <th>CXCR3</th>\n",
       "      <th>CD127</th>\n",
       "      <th>TIM3</th>\n",
       "      <th>CD45RA</th>\n",
       "      <th>ICOS</th>\n",
       "      <th>CD4</th>\n",
       "      <th>CD3</th>\n",
       "      <th>CCR6</th>\n",
       "      <th>PD1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340740</th>\n",
       "      <td>0.103427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174617</td>\n",
       "      <td>0.141331</td>\n",
       "      <td>0.038327</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>0.476414</td>\n",
       "      <td>0.173947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120253</td>\n",
       "      <td>0.241595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790657</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072121</td>\n",
       "      <td>0.214664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550223</td>\n",
       "      <td>0.615384</td>\n",
       "      <td>0.113164</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890756</th>\n",
       "      <td>0.119222</td>\n",
       "      <td>0.105180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038327</td>\n",
       "      <td>0.219516</td>\n",
       "      <td>0.056529</td>\n",
       "      <td>0.460911</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077609</td>\n",
       "      <td>0.644587</td>\n",
       "      <td>0.113164</td>\n",
       "      <td>0.083909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465676</th>\n",
       "      <td>0.299882</td>\n",
       "      <td>0.187862</td>\n",
       "      <td>0.097765</td>\n",
       "      <td>0.917641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769668</td>\n",
       "      <td>0.048604</td>\n",
       "      <td>0.027109</td>\n",
       "      <td>0.031381</td>\n",
       "      <td>0.745582</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425217</th>\n",
       "      <td>0.220598</td>\n",
       "      <td>0.036739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095411</td>\n",
       "      <td>0.229726</td>\n",
       "      <td>0.616662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           HLADR     CTLA4      CD25     CXCR5     CXCR3     CD127      TIM3  \\\n",
       "340740  0.103427  0.000000  0.174617  0.141331  0.038327  0.028797  0.476414   \n",
       "790657  0.000000  0.072121  0.214664  0.000000  0.000000  0.000000  0.000000   \n",
       "890756  0.119222  0.105180  0.000000  0.038327  0.219516  0.056529  0.460911   \n",
       "465676  0.299882  0.187862  0.097765  0.917641  0.000000  0.028797  0.000000   \n",
       "425217  0.220598  0.036739  0.000000  0.000000  0.038327  0.000000  0.316560   \n",
       "\n",
       "          CD45RA      ICOS       CD4       CD3      CCR6       PD1  \n",
       "340740  0.173947  0.000000  0.120253  0.241595  0.000000  0.000000  \n",
       "790657  0.632033  0.000000  0.550223  0.615384  0.113164  0.000000  \n",
       "890756  0.686022  0.000000  0.077609  0.644587  0.113164  0.083909  \n",
       "465676  0.769668  0.048604  0.027109  0.031381  0.745582  0.000000  \n",
       "425217  0.000000  0.095411  0.229726  0.616662  0.000000  0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# markers = NSCLC_markers + PBMC_markers\n",
    "dataset = MyDataset(df[overlap])\n",
    "# # Data loader\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=1000, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, latent_dim=5, hdim=50):\n",
    "        super(VAE, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc1 = nn.Linear(x_dim , hdim)\n",
    "        self.fc21 = nn.Linear(hdim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hdim, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hdim)\n",
    "        self.fc4 = nn.Linear(hdim, x_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x_ = torch.cat([x], dim=-1)\n",
    "        h1 = F.relu(self.fc1(x_))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return self.fc4(h3)\n",
    "    def reparameterize(self, mu, var):\n",
    "#         if self.distance == 'standard':\n",
    "        if self.training:\n",
    "            std = var.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            result = eps.mul(std).add_(mu)\n",
    "            return result\n",
    "        else:\n",
    "            return mu\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.x_dim))\n",
    "        latent = self.reparameterize(mu, logvar)\n",
    "        reconstructed = self.decode(latent)\n",
    "        return reconstructed, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y, device):\n",
    "    x_size = x.to(device).size(0)\n",
    "    y_size = y.to(device).size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1)\n",
    "    y = y.unsqueeze(0)\n",
    "    tiled_x = x.expand(x_size, y_size, dim).to(device)\n",
    "    tiled_y = y.expand(x_size, y_size, dim).to(device)\n",
    "    kernel_input = (tiled_x - tiled_y).pow(2).mean(2)/float(dim)\n",
    "    return torch.exp(-kernel_input)\n",
    "\n",
    "def compute_mmd(x, y, device):\n",
    "    x_kernel = compute_kernel(x, x, device)\n",
    "    y_kernel = compute_kernel(y, y, device)\n",
    "    xy_kernel = compute_kernel(x, y, device)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd\n",
    "\n",
    "def vae_loss_function(inputs, encoded, decoded, true_samples, device):\n",
    "    #reconstruction loss - decoding\n",
    "    nll = (decoded - inputs).pow(2).mean()\n",
    "    #distance + reconstruction loss\n",
    "    mmd = compute_mmd(true_samples, encoded.to(device), device)\n",
    "    return(nll, mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, learning_rate, epochs, train_loader, test_loader, optimizer = 'Adam'):\n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, \n",
    "                              momentum = .95, nesterov = True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0\n",
    "        training_reconstruction_error = 0\n",
    "        training_mmd = 0\n",
    "\n",
    "        net.train()\n",
    "        for batchnum, X in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            reconstruction, mu = net(X)\n",
    "            true_samples = torch.randn(mu.shape)\n",
    "            reconstruction_error, mmd = vae_loss_function(inputs = X, encoded=mu, decoded=reconstruction, true_samples=true_samples , device=device)\n",
    "            loss = reconstruction_error + mmd\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            training_reconstruction_error += reconstruction_error\n",
    "            training_mmd  += mmd\n",
    "            training_loss += loss\n",
    "\n",
    "        training_reconstruction_error /= (batchnum+1)\n",
    "        training_mmd  /= (batchnum+1)\n",
    "        training_loss /= (batchnum+1)\n",
    "        print('Training loss for epoch %i is %.8f, Reconstruction is %.8f, mmd is %.8f'%(epoch, training_loss, training_reconstruction_error, training_mmd) )\n",
    "        \n",
    "        #Testing loop\n",
    "\n",
    "        testing_reconstruction_error = 0\n",
    "        testing_mmd = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batchnum, X in enumerate(test_loader):\n",
    "                reconstruction, mu = net(X)\n",
    "                true_samples = torch.randn(mu.shape)\n",
    "                reconstruction_error, mmd = vae_loss_function(inputs = X, encoded=mu, decoded=reconstruction, true_samples=true_samples , device=device)\n",
    "\n",
    "                testing_reconstruction_error += reconstruction_error\n",
    "                testing_mmd += mmd\n",
    "            \n",
    "            testing_reconstruction_error /= (batchnum+1)\n",
    "            testing_mmd /= (batchnum+1)\n",
    "            print('Testing loss for epoch %i is %.8f, Reconstruction is %.8f, mmd is %.8f'%(epoch, testing_reconstruction_error + testing_mmd, testing_reconstruction_error, testing_mmd) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VAE(x_dim=dataset.x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 0 is 0.12598665, Reconstruction is 0.12377081, mmd is 0.00221584\n",
      "Testing loss for epoch 0 is 0.08257637, Reconstruction is 0.08142467, mmd is 0.00115170\n",
      "Training loss for epoch 1 is 0.06481549, Reconstruction is 0.06378343, mmd is 0.00103205\n",
      "Testing loss for epoch 1 is 0.05272894, Reconstruction is 0.05177472, mmd is 0.00095422\n",
      "Training loss for epoch 2 is 0.04706269, Reconstruction is 0.04607858, mmd is 0.00098410\n",
      "Testing loss for epoch 2 is 0.04296221, Reconstruction is 0.04200570, mmd is 0.00095652\n",
      "Training loss for epoch 3 is 0.04066073, Reconstruction is 0.03971995, mmd is 0.00094077\n",
      "Testing loss for epoch 3 is 0.03892866, Reconstruction is 0.03799993, mmd is 0.00092872\n",
      "Training loss for epoch 4 is 0.03783739, Reconstruction is 0.03695334, mmd is 0.00088404\n",
      "Testing loss for epoch 4 is 0.03694220, Reconstruction is 0.03608163, mmd is 0.00086057\n",
      "Training loss for epoch 5 is 0.03630543, Reconstruction is 0.03547177, mmd is 0.00083365\n",
      "Testing loss for epoch 5 is 0.03579091, Reconstruction is 0.03494294, mmd is 0.00084796\n",
      "Training loss for epoch 6 is 0.03526402, Reconstruction is 0.03449599, mmd is 0.00076803\n",
      "Testing loss for epoch 6 is 0.03488797, Reconstruction is 0.03410597, mmd is 0.00078201\n",
      "Training loss for epoch 7 is 0.03452031, Reconstruction is 0.03377408, mmd is 0.00074620\n",
      "Testing loss for epoch 7 is 0.03424991, Reconstruction is 0.03347938, mmd is 0.00077053\n",
      "Training loss for epoch 8 is 0.03387312, Reconstruction is 0.03319249, mmd is 0.00068063\n",
      "Testing loss for epoch 8 is 0.03367167, Reconstruction is 0.03293417, mmd is 0.00073750\n",
      "Training loss for epoch 9 is 0.03335650, Reconstruction is 0.03266214, mmd is 0.00069437\n",
      "Testing loss for epoch 9 is 0.03305706, Reconstruction is 0.03238608, mmd is 0.00067097\n",
      "Training loss for epoch 10 is 0.03275822, Reconstruction is 0.03211562, mmd is 0.00064260\n",
      "Testing loss for epoch 10 is 0.03253715, Reconstruction is 0.03183087, mmd is 0.00070629\n",
      "Training loss for epoch 11 is 0.03223619, Reconstruction is 0.03156052, mmd is 0.00067567\n",
      "Testing loss for epoch 11 is 0.03190661, Reconstruction is 0.03125798, mmd is 0.00064864\n",
      "Training loss for epoch 12 is 0.03160029, Reconstruction is 0.03091199, mmd is 0.00068829\n",
      "Testing loss for epoch 12 is 0.03120102, Reconstruction is 0.03052373, mmd is 0.00067729\n",
      "Training loss for epoch 13 is 0.03081087, Reconstruction is 0.03011144, mmd is 0.00069944\n",
      "Testing loss for epoch 13 is 0.03036040, Reconstruction is 0.02961918, mmd is 0.00074122\n",
      "Training loss for epoch 14 is 0.02981819, Reconstruction is 0.02906803, mmd is 0.00075017\n",
      "Testing loss for epoch 14 is 0.02939468, Reconstruction is 0.02853696, mmd is 0.00085772\n",
      "Training loss for epoch 15 is 0.02881176, Reconstruction is 0.02788184, mmd is 0.00092991\n",
      "Testing loss for epoch 15 is 0.02834843, Reconstruction is 0.02731161, mmd is 0.00103683\n",
      "Training loss for epoch 16 is 0.02784725, Reconstruction is 0.02672161, mmd is 0.00112564\n",
      "Testing loss for epoch 16 is 0.02744575, Reconstruction is 0.02614832, mmd is 0.00129743\n",
      "Training loss for epoch 17 is 0.02715269, Reconstruction is 0.02570064, mmd is 0.00145205\n",
      "Testing loss for epoch 17 is 0.02676018, Reconstruction is 0.02521386, mmd is 0.00154632\n",
      "Training loss for epoch 18 is 0.02642226, Reconstruction is 0.02481445, mmd is 0.00160781\n",
      "Testing loss for epoch 18 is 0.02620951, Reconstruction is 0.02443746, mmd is 0.00177205\n",
      "Training loss for epoch 19 is 0.02597518, Reconstruction is 0.02413729, mmd is 0.00183789\n",
      "Testing loss for epoch 19 is 0.02568885, Reconstruction is 0.02380961, mmd is 0.00187925\n",
      "Training loss for epoch 20 is 0.02548230, Reconstruction is 0.02353535, mmd is 0.00194694\n",
      "Testing loss for epoch 20 is 0.02529197, Reconstruction is 0.02326855, mmd is 0.00202342\n",
      "Training loss for epoch 21 is 0.02506827, Reconstruction is 0.02303134, mmd is 0.00203694\n",
      "Testing loss for epoch 21 is 0.02482653, Reconstruction is 0.02280432, mmd is 0.00202221\n",
      "Training loss for epoch 22 is 0.02465654, Reconstruction is 0.02260229, mmd is 0.00205426\n",
      "Testing loss for epoch 22 is 0.02442475, Reconstruction is 0.02238863, mmd is 0.00203612\n",
      "Training loss for epoch 23 is 0.02423178, Reconstruction is 0.02221293, mmd is 0.00201885\n",
      "Testing loss for epoch 23 is 0.02411459, Reconstruction is 0.02204467, mmd is 0.00206991\n",
      "Training loss for epoch 24 is 0.02388942, Reconstruction is 0.02184092, mmd is 0.00204850\n",
      "Testing loss for epoch 24 is 0.02362657, Reconstruction is 0.02166933, mmd is 0.00195724\n",
      "Training loss for epoch 25 is 0.02344688, Reconstruction is 0.02151306, mmd is 0.00193381\n",
      "Testing loss for epoch 25 is 0.02321053, Reconstruction is 0.02131918, mmd is 0.00189135\n",
      "Training loss for epoch 26 is 0.02308924, Reconstruction is 0.02115037, mmd is 0.00193887\n",
      "Testing loss for epoch 26 is 0.02286755, Reconstruction is 0.02094753, mmd is 0.00192001\n",
      "Training loss for epoch 27 is 0.02263401, Reconstruction is 0.02073980, mmd is 0.00189420\n",
      "Testing loss for epoch 27 is 0.02237594, Reconstruction is 0.02046639, mmd is 0.00190956\n",
      "Training loss for epoch 28 is 0.02213465, Reconstruction is 0.02019942, mmd is 0.00193522\n",
      "Testing loss for epoch 28 is 0.02178976, Reconstruction is 0.01985819, mmd is 0.00193157\n",
      "Training loss for epoch 29 is 0.02147697, Reconstruction is 0.01947840, mmd is 0.00199855\n",
      "Testing loss for epoch 29 is 0.02102925, Reconstruction is 0.01907254, mmd is 0.00195671\n"
     ]
    }
   ],
   "source": [
    "train(net, learning_rate = .0001, epochs = 30,\n",
    "      train_loader = train_loader, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'model_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=13, out_features=50, bias=True)\n",
       "  (fc21): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (fc22): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (fc3): Linear(in_features=5, out_features=50, bias=True)\n",
       "  (fc4): Linear(in_features=50, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load('model_state')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1034, 0.0000, 0.1746,  ..., 0.2416, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0721, 0.2147,  ..., 0.6154, 0.1132, 0.0000],\n",
       "        [0.1192, 0.1052, 0.0000,  ..., 0.6446, 0.1132, 0.0839],\n",
       "        ...,\n",
       "        [0.1249, 0.2198, 0.0829,  ..., 0.6044, 0.1242, 0.2148],\n",
       "        [0.2660, 0.1001, 0.0000,  ..., 0.1282, 0.0000, 0.2941],\n",
       "        [0.3818, 0.4265, 0.0225,  ..., 0.6453, 0.0000, 0.3827]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, latent = model(dataset.x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(latent, 'latent.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200000, 5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset.x_train, 'dataset_xtrain.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
